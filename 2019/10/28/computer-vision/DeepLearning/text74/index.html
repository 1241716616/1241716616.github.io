<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="一只行走的红烧肉" href="http://example.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="一只行走的红烧肉" href="http://example.com/atom.xml"><link rel="alternate" type="application/json" title="一只行走的红烧肉" href="http://example.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="PyTorch 深度学习"><link rel="canonical" href="http://example.com/2019/10/28/computer-vision/DeepLearning/text74/"><title>深度学习基础-数值稳定性和模型初始化 - 深度学习 - 计算机视觉 | 业余天王 = 一只行走的红烧肉 = 流水账</title><meta name="generator" content="Hexo 5.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">深度学习基础-数值稳定性和模型初始化</h1><div class="meta"><span class="item" title="创建时间：2019-10-28 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2019-10-28T00:00:00+08:00">2019-10-28</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>6.6k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>6 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">业余天王</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="http://pic.yupoo.com/1241716616/eeeaf753/5a262884.jpg"></li><li class="item" data-background-image="http://pic.yupoo.com/1241716616/7a98a089/1f37536f.jpg"></li><li class="item" data-background-image="http://pic.yupoo.com/1241716616/4bd7d1c3/f559f80e.jpg"></li><li class="item" data-background-image="http://pic.yupoo.com/1241716616/d6fdd759/65f6c50e.jpg"></li><li class="item" data-background-image="http://pic.yupoo.com/1241716616/c73e0f17/cc04950a.jpg"></li><li class="item" data-background-image="http://pic.yupoo.com/1241716616/feb367c2/a7bb740f.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer-vision/" itemprop="item" rel="index" title="分类于 计算机视觉"><span itemprop="name">计算机视觉</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer-vision/DeepLearning/" itemprop="item" rel="index" title="分类于 深度学习"><span itemprop="name">深度学习</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://example.com/2019/10/28/computer-vision/DeepLearning/text74/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/author.jpg"><meta itemprop="name" content="Mr.Wang"><meta itemprop="description" content="流水账, 一只行走的红烧肉"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="一只行走的红烧肉"></span><div class="body md" itemprop="articleBody"><h1 id="深度学习基础总结"><a class="anchor" href="#深度学习基础总结">#</a> 深度学习基础总结</h1><h2 id="实战kaggle比赛房价预测"><a class="anchor" href="#实战kaggle比赛房价预测">#</a> 实战 Kaggle 比赛：房价预测</h2><p>作为深度学习基础篇章的总结，下面，动手实战一个 Kaggle 比赛：房价预测。例子将提供未经调优的数据的预处理、模型的设计和超参数的选择。</p><p>这里需要在官网上自己注册 Kaggle 账号。房价预测比赛的网页地址是 <span class="exturl" data-url="aHR0cHM6Ly93d3cua2FnZ2xlLmNvbS9jL2hvdXNlLXByaWNlcy1hZHZhbmNlZC1yZWdyZXNzaW9uLXRlY2huaXF1ZXM=">https://www.kaggle.com/c/house-prices-advanced-regression-techniques</span> 。</p><h3 id="获取和读取数据集"><a class="anchor" href="#获取和读取数据集">#</a> 获取和读取数据集</h3><p>比赛数据分为训练数据集和测试数据集。两个数据集都包括每栋房子的特征，如街道类型、建造年份、房顶类型、地下室状况等特征值。这些特征值有连续的数字、离散的标签甚至是缺失值 “na”。只有训练数据集包括了每栋房子的价格，也就是标签。可以访问比赛网页，点击 “Data” 标签，并下载这些数据集。</p><p><img data-src="/images/textimages/text74/1.png" alt="1.png | center | 300x0"></p><p>下载后的数据位于我放在项目目录与 .py 文件同级目录下，使用 <code>pandas</code> 读取这两个文件。通过 <code>pandas</code> 库读入并处理数据。需要确保已安装 <code>pandas</code> 库。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果没有安装pandas，则反注释下面一行</span></span><br><span class="line"><span class="comment"># !pip install pandas</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch.utils.data</span><br><span class="line"><span class="keyword">import</span> utils <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br><span class="line">torch.set_default_tensor_type(torch.FloatTensor)</span><br><span class="line"></span><br><span class="line">train_data = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">print(train_data.shape)</span><br><span class="line">print(test_data.shape)</span><br><span class="line"><span class="comment">#查看前4个样本的前4个特征、后2个特征和标签（SalePrice）</span></span><br><span class="line">print(train_data.iloc[<span class="number">0</span>:<span class="number">4</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,-<span class="number">3</span>,-<span class="number">2</span>,-<span class="number">1</span>]])</span><br></pre></td></tr></table></figure><br>输出结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1460</span>, <span class="number">81</span>)</span><br><span class="line">(<span class="number">1459</span>, <span class="number">80</span>)</span><br></pre></td></tr></table></figure><br><img data-src="/images/textimages/text74/2.png" alt="2.png | center | 300x0"><p></p><p>可以看到训练数据集包括 1460 个样本、80 个特征和 1 个标签；测试数据集包括 1459 个样本和 80 个特征。我们需要将测试数据集中每个样本的标签预测出来。查看前 4 个样本的前 4 个特征、后 2 个特征和标签（SalePrice），可以看到第一个特征是 Id，它能帮助模型记住每个训练样本，但难以推广到测试样本，所以不使用它来训练。将所有的训练数据和测试数据的 79 个特征按样本连结。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_features = pd.concat((train_data.iloc[:,<span class="number">1</span>:-<span class="number">1</span>],test_data.iloc[:,<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><p></p><h3 id="预处理数据"><a class="anchor" href="#预处理数据">#</a> 预处理数据</h3><p>对连续数值的特征做标准化（standardization）：设该特征在整个数据集上的均值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">μ</span></span></span></span>，标准差为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span></span></span></span>。那么，可以将该特征的每个值先减去 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">μ</span></span></span></span> 再除以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span></span></span></span> 得到标准化后的每个特征值。对于缺失的特征值，我们将其替换成该特征的均值。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">numeric_features = all_features.dtypes[all_features.dtypes !=<span class="string">&#x27;object&#x27;</span>].index</span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class="line">    <span class="keyword">lambda</span> x: (x - x.mean()) / (x.std()))</span><br><span class="line"><span class="comment"># 标准化后，每个数值特征的均值变为0，所以可以直接用0来替换缺失值</span></span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].fillna(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p></p><p>接下来将离散数值转成指示特征。举个例子，假设特征 MSZoning 里面有两个不同的离散值 RL 和 RM，那么这一步转换将去掉 MSZoning 特征，并新加两个特征 MSZoning_RL 和 MSZoning_RM，其值为 0 或 1。如果一个样本原来在 MSZoning 里的值为 RL，那么有 MSZoning_RL=1 且 MSZoning_RM=0。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dummy_na=True将缺失值也当作合法的特征值并为其创建指示特征</span></span><br><span class="line">all_features = pd.get_dummies(all_features,dummy_na=<span class="literal">True</span>)</span><br><span class="line">print(all_features.shape) <span class="comment">#(2919, 331)</span></span><br></pre></td></tr></table></figure><p></p><p>可以看到这一步转换将特征数从 79 增加到了 331。</p><p>最后，通过 <code>values</code> 属性得到 NumPy 格式的数据，并转成 <code>NDArray</code> 方便后面的训练。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">n_train = train_data.shape[<span class="number">0</span>]</span><br><span class="line">train_features = torch.tensor(all_features[:n_train].values,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">test_features = torch.tensor(all_features[n_train:].values,dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">train_labels = torch.tensor(train_data.SalePrice.values,dtype=torch.<span class="built_in">float</span>).view(-<span class="number">1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p></p><h3 id="训练模型"><a class="anchor" href="#训练模型">#</a> 训练模型</h3><p>我们使用一个基本的线性回归模型和平方损失函数来训练模型。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss = torch.nn.MSELoss()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_net</span>(<span class="params">feature_num</span>):</span></span><br><span class="line">    net = nn.Linear(feature_num,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> net.parameters():</span><br><span class="line">        nn.init.normal_(param,mean=<span class="number">0</span>,std=<span class="number">0.01</span>)</span><br><span class="line">        <span class="keyword">return</span> net</span><br></pre></td></tr></table></figure><p></p><p>下面定义比赛用来评价模型的对数均方根误差。给定预测值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\hat y_1, \ldots, \hat y_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.69444em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.19444em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.69444em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.19444em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和对应的真实标签 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>y</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">y_1,\ldots, y_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>，它的定义为</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo fence="true">(</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow><mn>2</mn></msup></mrow></msqrt><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\sqrt{\frac{1}{n}\sum_{i=1}^n\left(\log(y_i)-\log(\hat y_i)\right)^2}.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.1568160000000005em;vertical-align:-1.277669em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791470000000006em"><span class="svg-align" style="top:-5.116816em"><span class="pstrut" style="height:5.116816em"></span><span class="mord" style="padding-left:1.056em"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0">(</span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.69444em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.19444em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.954008em"><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391470000000005em"><span class="pstrut" style="height:5.116816em"></span><span class="hide-tail" style="min-width:.742em;height:3.196816em"><svg width="400em" height="3.196816em" viewBox="0 0 400000 3196" preserveAspectRatio="xMinYMin slice"><path d="M702 80H40000040
H742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1
h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170
c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667
219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p><p>对数均方根误差的实现如下。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_rmse</span>(<span class="params">net,features,labels</span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># 将小于1的值设成1，使得取对数时数值更稳定</span></span><br><span class="line">        clipped_preds = torch.<span class="built_in">max</span>(net(features),torch.tensor(<span class="number">1.0</span>))</span><br><span class="line">        rmse = torch.sqrt(<span class="number">2</span> * loss(clipped_preds.log(),labels.log()).mean())</span><br><span class="line">    <span class="keyword">return</span> rmse.item()</span><br></pre></td></tr></table></figure><p></p><p>下面的训练函数跟前几节的不同在于使用了 Adam 优化算法。相对之前使用的小批量随机梯度下降，它对学习率相对不那么敏感。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">net,train_features,train_labels,test_features,test_labels,</span></span></span><br><span class="line"><span class="function"><span class="params">          num_epochs,learning_rate,weight_decay,batch_size</span>):</span></span><br><span class="line">    train_ls,test_ls = [],[]</span><br><span class="line">    dataset = torch.utils.data.TensorDataset(train_features,train_labels)</span><br><span class="line">    train_iter = torch.utils.data.DataLoader(dataset,batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.Adam(params=net.parameters(),lr=learning_rate,weight_decay=weight_decay)</span><br><span class="line">    net = net.<span class="built_in">float</span>()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> X,y <span class="keyword">in</span> train_iter:</span><br><span class="line">            l = loss(net(X.<span class="built_in">float</span>()),y.<span class="built_in">float</span>())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">        train_ls.append(log_rmse(net,train_features,train_labels))</span><br><span class="line">        <span class="keyword">if</span> test_labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            test_ls.append(log_rmse(net,test_features,test_labels))</span><br><span class="line">    <span class="keyword">return</span> train_ls,test_ls</span><br></pre></td></tr></table></figure><p></p><h3 id="k-折交叉验证"><a class="anchor" href="#k-折交叉验证">#</a> k 折交叉验证</h3><p>在<strong>模型选择、欠拟合和过拟合</strong>中介绍了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 折交叉验证。它将被用来选择模型设计并调节超参数。下面实现了一个函数，它返回第 <code>i</code> 折交叉验证时所需要的训练和验证数据。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_k_flod_data</span>(<span class="params">k,i,X,y</span>):</span></span><br><span class="line">    <span class="comment"># 返回第i折交叉验证时所需要的训练和验证数据</span></span><br><span class="line">    <span class="keyword">assert</span> k &gt;<span class="number">1</span></span><br><span class="line">    fold_size = X.shape[<span class="number">0</span>] // k</span><br><span class="line">    X_train,y_train = <span class="literal">None</span>,<span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        idx = <span class="built_in">slice</span>( j * fold_size,(j +<span class="number">1</span>) * fold_size)</span><br><span class="line">        X_part,y_part = X[idx,:],y[idx]</span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            X_valid,y_valid = X_part,y_part</span><br><span class="line">        <span class="keyword">elif</span> X_train <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            X_train,y_train = X_part,y_part</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X_train = torch.cat((X_train,X_part),dim=<span class="number">0</span>)</span><br><span class="line">            y_train = torch.cat((y_train,y_part),dim=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train,y_train,X_valid,y_valid</span><br></pre></td></tr></table></figure><p></p><p>在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 折交叉验证中我们训练<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 次并返回训练和验证的平均误差。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_fold</span>(<span class="params">k,X_train,y_train,num_epochs,</span></span></span><br><span class="line"><span class="function"><span class="params">           learning_rate,weight_decay,batch_size</span>):</span></span><br><span class="line">    train_l_sum,valid_l_sum = <span class="number">0</span>,<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        data = get_k_flod_data(k,i,X_train,y_train)</span><br><span class="line">        net = get_net(X_train.shape[<span class="number">1</span>])</span><br><span class="line">        train_ls,valid_ls = train(net,*data,num_epochs,learning_rate,</span><br><span class="line">                                  weight_decay,batch_size)</span><br><span class="line">        train_l_sum += train_ls[-<span class="number">1</span>]</span><br><span class="line">        valid_l_sum += valid_ls[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            d2l.semilogy(<span class="built_in">range</span>(<span class="number">1</span>,num_epochs + <span class="number">1</span>),train_ls,<span class="string">&#x27;epochs&#x27;</span>,<span class="string">&#x27;rmse&#x27;</span>,</span><br><span class="line">                         <span class="built_in">range</span>(<span class="number">1</span>,num_epochs + <span class="number">1</span>),valid_ls,[<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;valid&#x27;</span>])</span><br><span class="line">        print(<span class="string">&#x27;fold %d, train rmse %f,valid rmse %f&#x27;</span> %(i,train_ls[-<span class="number">1</span>],valid_ls[-<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">return</span> train_l_sum / k ,valid_l_sum /k</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><h3 id="模型选择"><a class="anchor" href="#模型选择">#</a> 模型选择</h3><p>使用一组未经调优的超参数并计算交叉验证误差。可以改动这些超参数来尽可能减小平均测试误差。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">k,num_epochs,lr,weight_decay,batch_size = <span class="number">5</span>,<span class="number">100</span>,<span class="number">5</span>,<span class="number">0</span>,<span class="number">64</span></span><br><span class="line">train_l,valid_l = k_fold(k,train_features,train_labels,num_epochs,lr,weight_decay,batch_size)</span><br><span class="line">print(<span class="string">&#x27;%d-fold validation: avg train rmse %f, avg valid rmse %f&#x27;</span> % (k, train_l, valid_l))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><br>输出结果：<p></p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fold <span class="number">0</span>, train rmse <span class="number">0.240393</span>,valid rmse <span class="number">0.222026</span></span><br><span class="line">fold <span class="number">1</span>, train rmse <span class="number">0.229521</span>,valid rmse <span class="number">0.267963</span></span><br><span class="line">fold <span class="number">2</span>, train rmse <span class="number">0.231740</span>,valid rmse <span class="number">0.238130</span></span><br><span class="line">fold <span class="number">3</span>, train rmse <span class="number">0.237747</span>,valid rmse <span class="number">0.218573</span></span><br><span class="line">fold <span class="number">4</span>, train rmse <span class="number">0.231194</span>,valid rmse <span class="number">0.258979</span></span><br><span class="line"><span class="number">5</span>-fold validation: avg train rmse <span class="number">0.234119</span>, avg valid rmse <span class="number">0.241134</span></span><br></pre></td></tr></table></figure><p></p><p>效果图<br><img data-src="/images/textimages/text74/3.png" alt="3.png | center | 300x0"></p><p>有时候你会发现一组参数的训练误差可以达到很低，但是在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 折交叉验证上的误差可能反而较高。这种现象很可能是由过拟合造成的。因此，当训练误差降低时，要观察 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 折交叉验证上的误差是否也相应降低。</p><h2 id="预测并在kaggle提交结果"><a class="anchor" href="#预测并在kaggle提交结果">#</a> 预测并在 Kaggle 提交结果</h2><p>下面定义预测函数。在预测之前，我们会使用完整的训练数据集来重新训练模型，并将预测结果存成提交所需要的格式。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_and_pred</span>(<span class="params">train_features,test_features,train_labels,test_data,</span></span></span><br><span class="line"><span class="function"><span class="params">                   num_epochs,lr,weight_decay,batch_size</span>):</span></span><br><span class="line">    net = get_net(train_features.shape[<span class="number">1</span>])</span><br><span class="line">    train_ls,_ = train(net,train_features,train_labels,<span class="literal">None</span>,<span class="literal">None</span>,</span><br><span class="line">                       num_epochs,lr,weight_decay,batch_size)</span><br><span class="line">    d2l.semilogy(<span class="built_in">range</span>(<span class="number">1</span>,num_epochs + <span class="number">1</span>),train_ls,<span class="string">&#x27;epochs&#x27;</span>,<span class="string">&#x27;rmse&#x27;</span>)</span><br><span class="line">    print(<span class="string">&#x27;train rmse %f&#x27;</span> % train_ls[-<span class="number">1</span>])</span><br><span class="line">    preds = net(test_features).detach().numpy()</span><br><span class="line">    test_data[<span class="string">&#x27;SalePrice&#x27;</span>] = pd.Series(preds.reshape(<span class="number">1</span>,-<span class="number">1</span>)[<span class="number">0</span>])</span><br><span class="line">    submission = pd.concat([test_data[<span class="string">&#x27;Id&#x27;</span>],test_data[<span class="string">&#x27;SalePrice&#x27;</span>]],axis=<span class="number">1</span>)</span><br><span class="line">    submission.to_csv(<span class="string">&#x27;./sunmission.csv&#x27;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p></p><p>设计好模型并调好超参数之后，下一步就是对测试数据集上的房屋样本做价格预测。如果得到与交叉验证时差不多的训练误差，那么这个结果很可能是理想的，可以在 Kaggle 上提交结果。</p><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_and_pred(train_features,test_features,train_labels,test_data,num_epochs,lr,weight_decay, batch_size)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><p>上述代码执行完之后会生成一个 submission.csv 文件。这个文件是符合 Kaggle 比赛要求的提交格式的。这时，可以在 Kaggle 上提交我们预测得出的结果，并且查看与测试数据集上真实房价（标签）的误差。具体来说有以下几个步骤：登录 Kaggle 网站，访问房价预测比赛网页，并点击右侧 <strong>Submit Predictions</strong> 或 <strong>Late Submission</strong> 按钮；然后，点击页面下方 <strong>Upload File</strong> 图标所在的虚线框选择需要提交的预测结果文件；最后，点击页面最下方的 <strong>Make Submission</strong> 按钮就可以查看结果了，如下图所示。</p><p><img data-src="/images/textimages/text74/5.png" alt="5.png | center | 300x0"></p><h3 id="总结"><a class="anchor" href="#总结">#</a> 总结</h3><ol><li>通常需要对真实数据做预处理。</li><li>可以使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> 折交叉验证来选择模型并调节超参数。</li></ol><div class="tags"><a href="/tags/PyTorch-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> PyTorch 深度学习</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2020-12-29 14:19:52" itemprop="dateModified" datetime="2020-12-29T14:19:52+08:00">2020-12-29</time> </span><span id="2019/10/28/computer-vision/DeepLearning/text74/" class="item leancloud_visitors" data-flag-title="深度学习基础-数值稳定性和模型初始化" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Mr.Wang <i class="ic i-at"><em>@</em></i>一只行走的红烧肉</li><li class="link"><strong>本文链接：</strong> <a href="http://example.com/2019/10/28/computer-vision/DeepLearning/text74/" title="深度学习基础-数值稳定性和模型初始化">http://example.com/2019/10/28/computer-vision/DeepLearning/text74/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2019/10/26/computer-vision/DeepLearning/text73/" itemprop="url" rel="prev" data-background-image="http:&#x2F;&#x2F;pic.yupoo.com&#x2F;1241716616&#x2F;d6fdd759&#x2F;65f6c50e.jpg" title="深度学习基础-数值稳定性和模型初始化"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 深度学习</span><h3>深度学习基础-数值稳定性和模型初始化</h3></a></div><div class="item right"><a href="/2020/02/16/computer-science/DataStructures/text75/" itemprop="url" rel="next" data-background-image="http:&#x2F;&#x2F;pic.yupoo.com&#x2F;1241716616&#x2F;96723e42&#x2F;3834540f.jpg" title="数据结构与算法-线性结构之堆栈及其顺序存储、链式存储"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 数据结构与算法</span><h3>数据结构与算法-线性结构之堆栈及其顺序存储、链式存储</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93"><span class="toc-number">1.</span> <span class="toc-text">深度学习基础总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E6%88%98kaggle%E6%AF%94%E8%B5%9B%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B"><span class="toc-number">1.1.</span> <span class="toc-text">实战 Kaggle 比赛：房价预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E5%92%8C%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.1.</span> <span class="toc-text">获取和读取数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.2.</span> <span class="toc-text">预处理数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.3.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">1.1.4.</span> <span class="toc-text">k 折交叉验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-number">1.1.5.</span> <span class="toc-text">模型选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%B9%B6%E5%9C%A8kaggle%E6%8F%90%E4%BA%A4%E7%BB%93%E6%9E%9C"><span class="toc-number">1.2.</span> <span class="toc-text">预测并在 Kaggle 提交结果</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.2.1.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2019/10/10/computer-vision/DeepLearning/text58/" rel="bookmark" title="PyTorch 开发环境的搭建">PyTorch 开发环境的搭建</a></li><li><a href="/2019/10/11/computer-vision/DeepLearning/text59/" rel="bookmark" title="PyTorch 快速入门">PyTorch 快速入门</a></li><li><a href="/2019/10/12/computer-vision/DeepLearning/text60/" rel="bookmark" title="深度学习基础-线性回归">深度学习基础-线性回归</a></li><li><a href="/2019/10/13/computer-vision/DeepLearning/text61/" rel="bookmark" title="深度学习基础-从零实现线性回归">深度学习基础-从零实现线性回归</a></li><li><a href="/2019/10/14/computer-vision/DeepLearning/text62/" rel="bookmark" title="深度学习基础-从零实现线性回归II">深度学习基础-从零实现线性回归II</a></li><li><a href="/2019/10/15/computer-vision/DeepLearning/text63/" rel="bookmark" title="深度学习基础-softmax回归">深度学习基础-softmax回归</a></li><li><a href="/2019/10/16/computer-vision/DeepLearning/text64/" rel="bookmark" title="深度学习基础-图像数据集">深度学习基础-图像数据集</a></li><li><a href="/2019/10/17/computer-vision/DeepLearning/text65/" rel="bookmark" title="深度学习基础-从零实现 softmax 回归">深度学习基础-从零实现 softmax 回归</a></li><li><a href="/2019/10/18/computer-vision/DeepLearning/text66/" rel="bookmark" title="深度学习基础-softmax回归的简洁实现">深度学习基础-softmax回归的简洁实现</a></li><li><a href="/2019/10/19/computer-vision/DeepLearning/text67/" rel="bookmark" title="深度学习基础-多层感知机">深度学习基础-多层感知机</a></li><li><a href="/2019/10/20/computer-vision/DeepLearning/text68/" rel="bookmark" title="深度学习基础-从零实现多层感知机">深度学习基础-从零实现多层感知机</a></li><li><a href="/2019/10/22/computer-vision/DeepLearning/text69/" rel="bookmark" title="深度学习基础-模型选择、欠拟合和过拟合">深度学习基础-模型选择、欠拟合和过拟合</a></li><li><a href="/2019/10/23/computer-vision/DeepLearning/text70/" rel="bookmark" title="深度学习基础-权重衰减">深度学习基础-权重衰减</a></li><li><a href="/2019/10/24/computer-vision/DeepLearning/text71/" rel="bookmark" title="深度学习基础-丢弃法">深度学习基础-丢弃法</a></li><li><a href="/2019/10/25/computer-vision/DeepLearning/text72/" rel="bookmark" title="深度学习基础-正向传播、反向传播和计算图">深度学习基础-正向传播、反向传播和计算图</a></li><li><a href="/2019/10/26/computer-vision/DeepLearning/text73/" rel="bookmark" title="深度学习基础-数值稳定性和模型初始化">深度学习基础-数值稳定性和模型初始化</a></li><li class="active"><a href="/2019/10/28/computer-vision/DeepLearning/text74/" rel="bookmark" title="深度学习基础-数值稳定性和模型初始化">深度学习基础-数值稳定性和模型初始化</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Mr.Wang" data-src="/images/author.jpg"><p class="name" itemprop="name">Mr.Wang</p><div class="description" itemprop="description">一只行走的红烧肉</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">87</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">10</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">13</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tLzEyNDE3MTY2MTY=" title="https:&#x2F;&#x2F;github.com&#x2F;1241716616"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;yourname"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTIxNDE1NzI1MjA=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;2141572520"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;about.me&#x2F;yourname"><i class="ic i-address-card"></i></span> <span class="exturl item email" data-url="bWFpbHRvOjEyNDE3MTY2MTZAcXEuY29t" title="mailto:1241716616@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>links</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2019/10/26/computer-vision/DeepLearning/text73/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2020/02/16/computer-science/DataStructures/text75/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/06/08/computer-vision/text27/" title="积分图像">积分图像</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/05/12/computer-vision/text14/" title="定义感兴趣区">定义感兴趣区</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/05/17/computer-vision/text18/" title="图像滤波">图像滤波</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/Webspider/" title="分类于 网页爬虫">网页爬虫</a></div><span><a href="/2019/08/28/computer-science/Webspider/text50/" title="数据解析">数据解析</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/06/26/computer-vision/text35/" title="图像分割实战-证件照背景替换">图像分割实战-证件照背景替换</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/07/29/computer-vision/text48/" title="OpenCV 深度神经网络（DNN）模块 - 基于CNN的年龄性别检测">OpenCV 深度神经网络（DNN）模块 - 基于CNN的年龄性别检测</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/07/07/computer-vision/text39/" title="视频分析与对象跟踪-CamShift 算法">视频分析与对象跟踪-CamShift 算法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/DeepLearning/" title="分类于 深度学习">深度学习</a></div><span><a href="/2019/10/17/computer-vision/DeepLearning/text65/" title="深度学习基础-从零实现 softmax 回归">深度学习基础-从零实现 softmax 回归</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/07/25/computer-vision/text45/" title="OpenCV 深度神经网络（DNN）模块 - 使用 goolenet 模型实现图像分类">OpenCV 深度神经网络（DNN）模块 - 使用 goolenet 模型实现图像分类</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-vision/" title="分类于 计算机视觉">计算机视觉</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-vision/Opencv/" title="分类于 OpenCV图像处理算法">OpenCV图像处理算法</a></div><span><a href="/2019/05/19/computer-vision/text19/" title="直方图">直方图</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Mr.Wang @ 业余天王</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">508k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">7:42</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2019/10/28/computer-vision/DeepLearning/text74/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html>